{
 "cells": [
  {
   "cell_type": "code",
   "source": "#@title <h1>Step 4: Advanced Tools & Utilities</h1> üõ†Ô∏è Professional-grade post-processing & analysis\n\n#@markdown ## üé® Video Enhancement Suite\nenhance_existing_video = \"\" #@param {type:\"string\"}\n\n#@markdown ### Enhancement Options\nupscale_resolution = \"2x\" #@param [\"1x\", \"2x\", \"4x\", \"8x\"]\nenhancement_model = \"RealESRGAN\" #@param [\"RealESRGAN\", \"GFPGAN\", \"CodeFormer\", \"ESRGAN\"]\nface_restoration_strength = 0.8 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n\n#@markdown ### Video Stabilization\nstabilize_video = False #@param {type:\"boolean\"}\nstabilization_method = \"VidStab\" #@param [\"VidStab\", \"OpenCV\", \"FFmpeg\"]\n\n#@markdown ### Color Grading & Correction\napply_color_grading = False #@param {type:\"boolean\"}\ncolor_temperature = 6500 #@param {type:\"slider\", min:2000, max:10000, step:100}\ntint_adjustment = 0 #@param {type:\"slider\", min:-100, max:100, step:5}\nexposure_compensation = 0.0 #@param {type:\"slider\", min:-2.0, max:2.0, step:0.1}\nhighlight_recovery = 0.0 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\nshadow_lift = 0.0 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n\n#@markdown ## üìä Quality Analysis Tools\nanalyze_video_quality = False #@param {type:\"boolean\"}\ngenerate_quality_metrics = True #@param {type:\"boolean\"}\ncreate_quality_plots = True #@param {type:\"boolean\"}\n\n#@markdown ### Comparison Analysis\ncompare_with_original = True #@param {type:\"boolean\"}\noriginal_video_path = \"\" #@param {type:\"string\"}\ncreate_side_by_side = True #@param {type:\"boolean\"}\ngenerate_difference_map = False #@param {type:\"boolean\"}\n\n#@markdown ## üîß Utility Functions\nconvert_video_format = False #@param {type:\"boolean\"}\ntarget_format = \"mp4\" #@param [\"mp4\", \"avi\", \"mov\", \"mkv\", \"webm\", \"gif\"]\nextract_frames = False #@param {type:\"boolean\"}\nframe_extraction_fps = 1 #@param {type:\"slider\", min:0.1, max:30, step:0.1}\n\n#@markdown ### Audio Enhancement\nenhance_audio = False #@param {type:\"boolean\"}\nnoise_reduction_strength = 0.5 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\naudio_normalization = True #@param {type:\"boolean\"}\nadd_reverb = False #@param {type:\"boolean\"}\n\n#@markdown ## üöÄ Execute Advanced Processing\n\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image, ImageEnhance\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport json\nimport subprocess\nimport time\n\ndef enhance_video_quality(input_path, output_path, enhancement_settings):\n    \\\"\\\"\\\"Apply video enhancement using selected models\\\"\\\"\\\"\n    print(f\"üé® Enhancing video: {os.path.basename(input_path)}\")\n    \n    try:\n        # Video enhancement implementation would go here\n        # This is a placeholder for the actual enhancement logic\n        \n        if enhancement_settings['upscale_resolution'] != \"1x\":\n            print(f\"  üìà Upscaling to {enhancement_settings['upscale_resolution']}\")\n            \n        if enhancement_settings['face_restoration_strength'] > 0:\n            print(f\"  üë§ Face restoration strength: {enhancement_settings['face_restoration_strength']}\")\n            \n        # Placeholder: Copy original for now (in real implementation, apply enhancements)\n        import shutil\n        shutil.copy2(input_path, output_path)\n        \n        return True\n    except Exception as e:\n        print(f\"‚ùå Enhancement failed: {e}\")\n        return False\n\ndef analyze_video_quality_metrics(video_path):\n    \\\"\\\"\\\"Analyze video quality and generate metrics\\\"\\\"\\\"\n    print(f\"üìä Analyzing video quality: {os.path.basename(video_path)}\")\n    \n    try:\n        cap = cv2.VideoCapture(video_path)\n        \n        metrics = {\n            'resolution': (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))),\n            'fps': cap.get(cv2.CAP_PROP_FPS),\n            'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n            'duration': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / cap.get(cv2.CAP_PROP_FPS),\n            'codec': int(cap.get(cv2.CAP_PROP_FOURCC)),\n            'bitrate': None  # Would need ffprobe for this\n        }\n        \n        # Sample frames for quality analysis\n        frame_metrics = []\n        sample_count = min(50, int(metrics['frame_count']))\n        \n        for i in range(sample_count):\n            cap.set(cv2.CAP_PROP_POS_FRAMES, i * (metrics['frame_count'] // sample_count))\n            ret, frame = cap.read()\n            \n            if ret:\n                # Calculate basic quality metrics\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                \n                # Sharpness (Laplacian variance)\n                sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n                \n                # Brightness (mean pixel value)\n                brightness = np.mean(gray)\n                \n                # Contrast (standard deviation)\n                contrast = np.std(gray)\n                \n                frame_metrics.append({\n                    'frame': i,\n                    'sharpness': sharpness,\n                    'brightness': brightness,\n                    'contrast': contrast\n                })\n        \n        cap.release()\n        \n        # Calculate aggregate metrics\n        avg_sharpness = np.mean([m['sharpness'] for m in frame_metrics])\n        avg_brightness = np.mean([m['brightness'] for m in frame_metrics])\n        avg_contrast = np.mean([m['contrast'] for m in frame_metrics])\n        \n        metrics.update({\n            'avg_sharpness': avg_sharpness,\n            'avg_brightness': avg_brightness,\n            'avg_contrast': avg_contrast,\n            'frame_metrics': frame_metrics\n        })\n        \n        return metrics\n        \n    except Exception as e:\n        print(f\"‚ùå Quality analysis failed: {e}\")\n        return None\n\ndef create_quality_visualization(metrics, output_dir):\n    \\\"\\\"\\\"Create quality analysis visualizations\\\"\\\"\\\"\n    try:\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        fig.suptitle('Video Quality Analysis', fontsize=16, fontweight='bold')\n        \n        frame_nums = [m['frame'] for m in metrics['frame_metrics']]\n        sharpness_vals = [m['sharpness'] for m in metrics['frame_metrics']]\n        brightness_vals = [m['brightness'] for m in metrics['frame_metrics']]\n        contrast_vals = [m['contrast'] for m in metrics['frame_metrics']]\n        \n        # Sharpness over time\n        axes[0, 0].plot(frame_nums, sharpness_vals, 'b-', alpha=0.7)\n        axes[0, 0].set_title('Sharpness Over Time')\n        axes[0, 0].set_xlabel('Frame')\n        axes[0, 0].set_ylabel('Sharpness Score')\n        axes[0, 0].grid(True, alpha=0.3)\n        \n        # Brightness histogram\n        axes[0, 1].hist(brightness_vals, bins=20, alpha=0.7, color='orange')\n        axes[0, 1].axvline(metrics['avg_brightness'], color='red', linestyle='--', \n                          label=f'Average: {metrics[\"avg_brightness\"]:.1f}')\n        axes[0, 1].set_title('Brightness Distribution')\n        axes[0, 1].set_xlabel('Brightness')\n        axes[0, 1].set_ylabel('Frequency')\n        axes[0, 1].legend()\n        \n        # Contrast over time\n        axes[1, 0].plot(frame_nums, contrast_vals, 'g-', alpha=0.7)\n        axes[1, 0].set_title('Contrast Over Time')\n        axes[1, 0].set_xlabel('Frame')\n        axes[1, 0].set_ylabel('Contrast Score')\n        axes[1, 0].grid(True, alpha=0.3)\n        \n        # Summary metrics\n        summary_data = [\n            ['Resolution', f\"{metrics['resolution'][0]}x{metrics['resolution'][1]}\"],\n            ['FPS', f\"{metrics['fps']:.2f}\"],\n            ['Duration', f\"{metrics['duration']:.2f}s\"],\n            ['Avg Sharpness', f\"{metrics['avg_sharpness']:.2f}\"],\n            ['Avg Brightness', f\"{metrics['avg_brightness']:.2f}\"],\n            ['Avg Contrast', f\"{metrics['avg_contrast']:.2f}\"]\n        ]\n        \n        axes[1, 1].axis('off')\n        table = axes[1, 1].table(cellText=summary_data,\n                                colLabels=['Metric', 'Value'],\n                                cellLoc='left',\n                                loc='center',\n                                colWidths=[0.4, 0.4])\n        table.auto_set_font_size(False)\n        table.set_fontsize(10)\n        table.scale(1, 2)\n        axes[1, 1].set_title('Video Summary')\n        \n        plt.tight_layout()\n        \n        # Save plot\n        plot_path = os.path.join(output_dir, 'quality_analysis.png')\n        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"üìà Quality analysis plot saved: {plot_path}\")\n        return plot_path\n        \n    except Exception as e:\n        print(f\"‚ùå Visualization creation failed: {e}\")\n        return None\n\ndef create_comparison_video(original_path, processed_path, output_path):\n    \\\"\\\"\\\"Create side-by-side comparison video\\\"\\\"\\\"\n    print(\"üé¨ Creating comparison video...\")\n    \n    try:\n        # FFmpeg command for side-by-side comparison\n        cmd = [\n            'ffmpeg', '-y',\n            '-i', original_path,\n            '-i', processed_path,\n            '-filter_complex', '[0:v][1:v]hstack=inputs=2[v]',\n            '-map', '[v]',\n            '-c:v', 'libx264',\n            '-crf', '18',\n            '-preset', 'fast',\n            output_path\n        ]\n        \n        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n        \n        if result.returncode == 0:\n            print(f\"‚úÖ Comparison video created: {output_path}\")\n            return True\n        else:\n            print(f\"‚ùå Comparison creation failed: {result.stderr}\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå Comparison video creation failed: {e}\")\n        return False\n\n# Main execution logic\nprint(\"üõ†Ô∏è Starting Advanced Processing & Analysis...\")\n\n# Create output directory for this session\nsession_dir = f\"outputs/advanced_session_{int(time.time())}\"\nos.makedirs(session_dir, exist_ok=True)\n\n# Video Enhancement\nif enhance_existing_video and os.path.exists(enhance_existing_video):\n    print(\"\\nüé® === Video Enhancement ===\")\n    \n    enhancement_settings = {\n        'upscale_resolution': upscale_resolution,\n        'enhancement_model': enhancement_model,\n        'face_restoration_strength': face_restoration_strength\n    }\n    \n    enhanced_path = os.path.join(session_dir, f\"enhanced_{os.path.basename(enhance_existing_video)}\")\n    \n    if enhance_video_quality(enhance_existing_video, enhanced_path, enhancement_settings):\n        print(f\"‚úÖ Enhanced video saved: {enhanced_path}\")\n        \n        # Video Stabilization\n        if stabilize_video:\n            print(\"üìπ Applying video stabilization...\")\n            stabilized_path = os.path.join(session_dir, f\"stabilized_{os.path.basename(enhance_existing_video)}\")\n            # Stabilization implementation would go here\n            print(f\"  üìπ Stabilization method: {stabilization_method}\")\n    \n# Quality Analysis\nif analyze_video_quality and enhance_existing_video:\n    print(\"\\nüìä === Quality Analysis ===\")\n    \n    metrics = analyze_video_quality_metrics(enhance_existing_video)\n    if metrics:\n        # Save metrics to JSON\n        metrics_path = os.path.join(session_dir, 'quality_metrics.json')\n        with open(metrics_path, 'w') as f:\n            json.dump(metrics, f, indent=2, default=str)\n        print(f\"üìã Quality metrics saved: {metrics_path}\")\n        \n        # Create visualizations\n        if create_quality_plots:\n            create_quality_visualization(metrics, session_dir)\n        \n        # Display key metrics\n        print(\"\\nüìà Key Quality Metrics:\")\n        print(f\"  Resolution: {metrics['resolution'][0]}x{metrics['resolution'][1]}\")\n        print(f\"  FPS: {metrics['fps']:.2f}\")\n        print(f\"  Duration: {metrics['duration']:.2f}s\")\n        print(f\"  Average Sharpness: {metrics['avg_sharpness']:.2f}\")\n        print(f\"  Average Brightness: {metrics['avg_brightness']:.2f}\")\n        print(f\"  Average Contrast: {metrics['avg_contrast']:.2f}\")\n\n# Comparison Analysis\nif compare_with_original and original_video_path and enhance_existing_video:\n    print(\"\\nüîç === Comparison Analysis ===\")\n    \n    if create_side_by_side:\n        comparison_path = os.path.join(session_dir, 'comparison_side_by_side.mp4')\n        create_comparison_video(original_video_path, enhance_existing_video, comparison_path)\n\n# Audio Enhancement\nif enhance_audio and enhance_existing_video:\n    print(\"\\nüéµ === Audio Enhancement ===\")\n    print(f\"  Noise reduction strength: {noise_reduction_strength}\")\n    print(f\"  Audio normalization: {audio_normalization}\")\n    print(f\"  Add reverb: {add_reverb}\")\n    print(\"  (Audio enhancement implementation in development)\")\n\n# Format Conversion\nif convert_video_format and enhance_existing_video:\n    print(f\"\\nüîÑ === Format Conversion to {target_format.upper()} ===\")\n    converted_path = os.path.join(session_dir, f\"converted.{target_format}\")\n    \n    cmd = [\n        'ffmpeg', '-y', '-i', enhance_existing_video,\n        '-c:v', 'libx264', '-crf', '18',\n        '-c:a', 'aac', '-b:a', '192k',\n        converted_path\n    ]\n    \n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n        if result.returncode == 0:\n            print(f\"‚úÖ Video converted: {converted_path}\")\n        else:\n            print(f\"‚ùå Conversion failed: {result.stderr}\")\n    except Exception as e:\n        print(f\"‚ùå Conversion error: {e}\")\n\n# Frame Extraction\nif extract_frames and enhance_existing_video:\n    print(f\"\\nüì∏ === Frame Extraction (FPS: {frame_extraction_fps}) ===\")\n    frames_dir = os.path.join(session_dir, 'extracted_frames')\n    os.makedirs(frames_dir, exist_ok=True)\n    \n    cmd = [\n        'ffmpeg', '-y', '-i', enhance_existing_video,\n        '-vf', f'fps={frame_extraction_fps}',\n        os.path.join(frames_dir, 'frame_%04d.png')\n    ]\n    \n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n        if result.returncode == 0:\n            frame_count = len(os.listdir(frames_dir))\n            print(f\"‚úÖ Extracted {frame_count} frames to: {frames_dir}\")\n        else:\n            print(f\"‚ùå Frame extraction failed: {result.stderr}\")\n    except Exception as e:\n        print(f\"‚ùå Frame extraction error: {e}\")\n\nprint(f\"\\nüìÅ All outputs saved to: {session_dir}\")\nprint(\"üéâ Advanced processing complete!\")\n\n# Display session summary\nif os.path.exists(session_dir):\n    files = os.listdir(session_dir)\n    if files:\n        print(f\"\\nüìÇ Session Files ({len(files)} items):\")\n        for file in sorted(files):\n            size_mb = os.path.getsize(os.path.join(session_dir, file)) / (1024*1024)\n            print(f\"  üìÑ {file} ({size_mb:.1f} MB)\")\n    else:\n        print(\"\\nüì≠ No files were generated in this session.\")\nelse:\n    print(\"\\n‚ö†Ô∏è No processing was performed. Please specify input files and enable desired features.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#@title <h1>Step 3: Batch Processing & Advanced Tools</h1> üöÄ Process multiple files efficiently\n\n#@markdown ## üì¶ Batch Processing Options\nbatch_input_directory = \"\" #@param {type:\"string\"}\nbatch_audio_directory = \"\" #@param {type:\"string\"}\n\n#@markdown ### File Matching Options\nfile_matching_mode = \"by_name\" #@param [\"by_name\", \"by_order\", \"single_audio\", \"manual_pairs\"]\nfile_extensions = \"mp4,avi,mov,mkv\" #@param {type:\"string\"}\naudio_extensions = \"wav,mp3,aac,m4a\" #@param {type:\"string\"}\n\n#@markdown ### Processing Options\nparallel_processing = True #@param {type:\"boolean\"}\nmax_concurrent_jobs = 2 #@param {type:\"slider\", min:1, max:4, step:1}\ncontinue_on_error = True #@param {type:\"boolean\"}\ncreate_progress_log = True #@param {type:\"boolean\"}\n\n#@markdown ## üé® Advanced Post-Processing\nenable_stabilization = False #@param {type:\"boolean\"}\nenable_denoising = False #@param {type:\"boolean\"}\nenable_sharpening = False #@param {type:\"boolean\"}\nenable_color_grading = False #@param {type:\"boolean\"}\n\n#@markdown ### Stabilization Settings\nstabilization_strength = 0.5 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\ncrop_for_stabilization = True #@param {type:\"boolean\"}\n\n#@markdown ### Enhancement Settings\ndenoising_strength = 0.3 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\nsharpening_amount = 0.2 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n\n#@markdown ## üìä Quality Analysis & Comparison\nenable_quality_metrics = True #@param {type:\"boolean\"}\ncreate_side_by_side_comparison = False #@param {type:\"boolean\"}\ngenerate_quality_report = True #@param {type:\"boolean\"}\n\n#@markdown ## üéØ Execute Batch Processing\n#@markdown Click play to start batch processing! ‚¨ÖÔ∏è\n\nimport os\nimport json\nimport glob\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nimport subprocess\nfrom tqdm import tqdm\nimport time\n\ndef find_matching_files(video_dir, audio_dir, matching_mode):\n    \\\"\\\"\\\"Find matching video and audio files based on the specified mode\\\"\\\"\\\"\n    video_files = []\n    audio_files = []\n    \n    # Get video files\n    for ext in file_extensions.split(','):\n        pattern = os.path.join(video_dir, f\"*.{ext.strip()}\")\n        video_files.extend(glob.glob(pattern))\n    \n    # Get audio files if directory specified\n    if audio_dir:\n        for ext in audio_extensions.split(','):\n            pattern = os.path.join(audio_dir, f\"*.{ext.strip()}\")\n            audio_files.extend(glob.glob(pattern))\n    \n    pairs = []\n    \n    if matching_mode == \"by_name\":\n        # Match by filename (without extension)\n        for video_file in video_files:\n            video_name = Path(video_file).stem\n            matching_audio = None\n            \n            for audio_file in audio_files:\n                audio_name = Path(audio_file).stem\n                if video_name == audio_name:\n                    matching_audio = audio_file\n                    break\n            \n            pairs.append((video_file, matching_audio))\n    \n    elif matching_mode == \"by_order\":\n        # Match by file order (alphabetical)\n        video_files.sort()\n        audio_files.sort()\n        \n        for i, video_file in enumerate(video_files):\n            audio_file = audio_files[i] if i < len(audio_files) else None\n            pairs.append((video_file, audio_file))\n    \n    elif matching_mode == \"single_audio\":\n        # Use single audio file for all videos\n        single_audio = audio_files[0] if audio_files else None\n        for video_file in video_files:\n            pairs.append((video_file, single_audio))\n    \n    return pairs\n\ndef process_single_file(video_file, audio_file, config_template, output_dir):\n    \\\"\\\"\\\"Process a single video file with enhanced error handling\\\"\\\"\\\"\n    try:\n        # Create unique config for this file\n        config = configparser.ConfigParser()\n        config.read_string(config_template)\n        \n        # Update paths\n        config['OPTIONS']['video_file'] = video_file\n        config['OPTIONS']['vocal_file'] = audio_file or ''\n        \n        # Create output filename\n        video_name = Path(video_file).stem\n        output_file = os.path.join(output_dir, f\"{video_name}_processed.mp4\")\n        config['OPTIONS']['output_file'] = output_file\n        \n        # Save config\n        config_path = f\"temp/config_{video_name}.ini\"\n        with open(config_path, 'w') as f:\n            config.write(f)\n        \n        # Run processing\n        result = subprocess.run(\n            [\"python\", \"run.py\", \"--config\", config_path],\n            capture_output=True, text=True, timeout=3600  # 1 hour timeout\n        )\n        \n        if result.returncode == 0:\n            return {\"status\": \"success\", \"file\": video_file, \"output\": output_file}\n        else:\n            return {\"status\": \"error\", \"file\": video_file, \"error\": result.stderr}\n            \n    except Exception as e:\n        return {\"status\": \"error\", \"file\": video_file, \"error\": str(e)}\n\n# Batch processing execution\nif batch_input_directory:\n    print(\"üöÄ Starting Enhanced Batch Processing...\")\n    \n    # Validate directories\n    if not os.path.exists(batch_input_directory):\n        print(f\"‚ùå Video directory not found: {batch_input_directory}\")\n    else:\n        # Find file pairs\n        file_pairs = find_matching_files(\n            batch_input_directory, \n            batch_audio_directory or \"\", \n            file_matching_mode\n        )\n        \n        if not file_pairs:\n            print(\"‚ùå No video files found in the specified directory\")\n        else:\n            print(f\"üìÅ Found {len(file_pairs)} video files to process\")\n            \n            # Create output directory\n            output_dir = os.path.join(\"outputs\", \"batch_\" + str(int(time.time())))\n            os.makedirs(output_dir, exist_ok=True)\n            \n            # Prepare config template\n            with open('config.ini', 'r') as f:\n                config_template = f.read()\n            \n            # Initialize results tracking\n            results = []\n            progress_log = []\n            \n            if parallel_processing and max_concurrent_jobs > 1:\n                # Parallel processing\n                print(f\"‚ö° Using {max_concurrent_jobs} parallel workers\")\n                \n                with ThreadPoolExecutor(max_workers=max_concurrent_jobs) as executor:\n                    futures = []\n                    \n                    for video_file, audio_file in file_pairs:\n                        future = executor.submit(\n                            process_single_file, \n                            video_file, audio_file, config_template, output_dir\n                        )\n                        futures.append(future)\n                    \n                    # Process results with progress bar\n                    for future in tqdm(futures, desc=\"Processing files\"):\n                        result = future.result()\n                        results.append(result)\n                        \n                        if create_progress_log:\n                            progress_entry = {\n                                \"timestamp\": time.time(),\n                                \"file\": result[\"file\"],\n                                \"status\": result[\"status\"]\n                            }\n                            progress_log.append(progress_entry)\n                        \n                        if result[\"status\"] == \"success\":\n                            print(f\"‚úÖ Completed: {os.path.basename(result['file'])}\")\n                        else:\n                            print(f\"‚ùå Failed: {os.path.basename(result['file'])} - {result.get('error', 'Unknown error')}\")\n                            if not continue_on_error:\n                                break\n            else:\n                # Sequential processing\n                print(\"üîÑ Processing files sequentially...\")\n                \n                for video_file, audio_file in tqdm(file_pairs, desc=\"Processing files\"):\n                    result = process_single_file(video_file, audio_file, config_template, output_dir)\n                    results.append(result)\n                    \n                    if create_progress_log:\n                        progress_entry = {\n                            \"timestamp\": time.time(),\n                            \"file\": result[\"file\"],\n                            \"status\": result[\"status\"]\n                        }\n                        progress_log.append(progress_entry)\n                    \n                    if result[\"status\"] == \"success\":\n                        print(f\"‚úÖ Completed: {os.path.basename(result['file'])}\")\n                    else:\n                        print(f\"‚ùå Failed: {os.path.basename(result['file'])} - {result.get('error', 'Unknown error')}\")\n                        if not continue_on_error:\n                            break\n            \n            # Generate summary report\n            successful = [r for r in results if r[\"status\"] == \"success\"]\n            failed = [r for r in results if r[\"status\"] == \"error\"]\n            \n            print(f\"\\nüìä Batch Processing Summary:\")\n            print(f\"  ‚úÖ Successful: {len(successful)}\")\n            print(f\"  ‚ùå Failed: {len(failed)}\")\n            print(f\"  üìÅ Output directory: {output_dir}\")\n            \n            # Save detailed report\n            if generate_quality_report:\n                report = {\n                    \"summary\": {\n                        \"total_files\": len(file_pairs),\n                        \"successful\": len(successful),\n                        \"failed\": len(failed),\n                        \"output_directory\": output_dir\n                    },\n                    \"detailed_results\": results,\n                    \"progress_log\": progress_log if create_progress_log else []\n                }\n                \n                report_path = os.path.join(output_dir, \"batch_processing_report.json\")\n                with open(report_path, 'w') as f:\n                    json.dump(report, f, indent=2)\n                print(f\"üìã Detailed report saved: {report_path}\")\n            \n            # Create comparison videos if requested\n            if create_side_by_side_comparison and len(successful) > 0:\n                print(\"üé¨ Creating comparison videos...\")\n                # Implementation for side-by-side comparison would go here\n                print(\"  (Comparison video creation is in development)\")\n            \n            print(\"\\nüéâ Batch processing complete!\")\n            \nelse:\n    print(\"‚ÑπÔ∏è Enter a batch_input_directory to enable batch processing\")\n    print(\"üìö Individual file processing is available in Step 2\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/anothermartz/Easy-Wav2Lip/blob/v8.3/Easy_Wav2Lip_v8.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkoF-mm8CGfB"
   },
   "source": [
    "Welcome to my Easy Wav2Lip colab!\n",
    "\n",
    "My goal is to make lipsyncing with this tool easy, fast and great looking!\n",
    "\n",
    "Please view the GitHub for instructions: [https://github.com/anothermartz/Easy-Wav2Lip](https://github.com/anothermartz/Easy-Wav2Lip?tab=readme-ov-file#best-practices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZJJ-zPGiiIs",
    "cellView": "form"
   },
   "outputs": [],
   "source": "version = 'v8.3'\n#@title <h1>Step 1: Setup \"Easy-Wav2Lip\" Enhanced</h1> One-click installation with advanced features!\n#@markdown üëà Click the play button to start - it will request Google Drive access: <br>\n#@markdown > Accept if your files are on Google Drive (recommended).\n#@markdown <br> Alternatively, you can click deny and upload files manually.\n\n#check if already installed\nimport os\nimport sys\nif os.path.exists('installed.txt'):\n  with open('last_file.txt', 'r') as file:\n    last_file = file.readline()\n  if last_file == version:\n    print('Easy-Wav2Lip '+version+' is already installed!')\n    print('Proceeding to Step 2...')\n  else:\n    print('Updating to version '+version+'...')\n\n#check GPU is enabled\nprint('üîç Checking for GPU availability...')\nimport torch\nif not torch.cuda.is_available():\n  sys.exit('‚ùå No GPU in runtime. Please go to \"Runtime\" ‚Üí \"Change runtime type\" ‚Üí Select \"GPU\".')\nelse:\n  print(f'‚úÖ GPU detected: {torch.cuda.get_device_name()}')\n  print(f'   VRAM available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n\n#prompt to mount google drive\nprint('üîó Requesting Google Drive access...')\ntry:\n  from google.colab import drive\n  drive.mount('/content/drive')\n  print('‚úÖ Google Drive mounted successfully')\nexcept:\n  print(\"‚ö†Ô∏è Google Drive not linked - you'll need to upload files manually\")\n\n#start timer\nimport time\nstart_time = time.time()\n\n#clone git\ngiturl = 'https://github.com/anothermartz/Easy-Wav2Lip.git'\n\nprint('üì• Downloading Easy-Wav2Lip...')\n!git clone -b {version} {giturl}\n%cd 'Easy-Wav2Lip'\nworking_directory = os.getcwd()\n!mkdir -p 'face_alignment' 'temp' 'outputs' 'batch_inputs'\n\n#install enhanced prerequisites\nprint('üì¶ Installing enhanced dependencies...')\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning,\n                        module='torchvision.transforms.functional_tensor')\n\n# Enhanced package installation with progress tracking\npackages = [\n    'batch_face',\n    'basicsr==1.4.2',\n    'gfpgan',\n    'realesrgan',\n    'codeformer',\n    'insightface',\n    'onnxruntime-gpu',\n    'gradio',\n    'ipywidgets',\n    'matplotlib',\n    'seaborn',\n    'plotly',\n    'ffmpeg-python',\n    'moviepy',\n    'imageio[ffmpeg]',\n    'scikit-image',\n    'face-alignment',\n    'yolov5'\n]\n\nfrom tqdm import tqdm\nimport subprocess\n\nfor i, package in enumerate(tqdm(packages, desc=\"Installing packages\")):\n    try:\n        if package == 'batch_face':\n            !pip install batch_face --quiet\n        elif package == 'basicsr==1.4.2':\n            !pip install basicsr==1.4.2 --quiet\n            print('üîß Fixing basicsr degradations.py...')\n            !cp /content/Easy-Wav2Lip/degradations.py /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\n        else:\n            subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--quiet'], \n                         capture_output=True, text=True)\n    except Exception as e:\n        print(f'‚ö†Ô∏è Warning: Failed to install {package}: {e}')\n\nprint('üîß Running installation script...')\n!python install.py\n\n# Create configuration directories\n!mkdir -p configs/presets\n!mkdir -p outputs/{version}\n\nprint('üìù Creating enhanced configuration files...')\n# Create preset configurations\npresets = {\n    'high_quality': {\n        'quality': 'Enhanced',\n        'sr_model': 'gfpgan',\n        'mask_feathering': 2.0,\n        'mask_size': 1.8,\n        'output_height': 'full resolution'\n    },\n    'fast_processing': {\n        'quality': 'Fast',\n        'output_height': '480',\n        'nosmooth': True\n    },\n    'balanced': {\n        'quality': 'Improved',\n        'mask_feathering': 1.5,\n        'output_height': '720'\n    }\n}\n\nimport json\nwith open('configs/presets/default_presets.json', 'w') as f:\n    json.dump(presets, f, indent=2)\n\nfrom IPython.display import clear_output\nclear_output()\nprint(\"üéâ Enhanced installation complete!\")\nprint(\"‚ú® New features available:\")\nprint(\"  ‚Ä¢ Advanced quality presets\")\nprint(\"  ‚Ä¢ Multiple super-resolution models\")\nprint(\"  ‚Ä¢ Batch processing capabilities\")\nprint(\"  ‚Ä¢ Real-time preview options\")\nprint(\"  ‚Ä¢ Advanced face detection\")\nprint(\"  ‚Ä¢ Custom output formats\")\nprint(\"\")\nprint(\"üìç Move to Step 2 to get started!\")\n\n#end timer\nelapsed_time = time.time() - start_time\nfrom easy_functions import format_time\nprint(f\"‚è±Ô∏è Setup time: {format_time(elapsed_time)}\")\n\n# Mark installation as complete\nwith open('installed.txt', 'w') as f:\n    f.write(version)\nwith open('last_file.txt', 'w') as f:\n    f.write(version)"
  },
  {
   "cell_type": "code",
   "source": "if not os.path.exists('installed.txt'):\n  sys.exit('‚ùå Step 1 has not been run! Please run Step 1 first.')\n\n#@title <h1>Step 2: Enhanced Wav2Lip Configuration</h1> üé¨ Professional-grade lip sync options\n#@markdown ## üìÅ Input Files\n#@markdown **Desktop**: Click folder icon (üìÅ) ‚Üí right-click file ‚Üí copy path<br>\n#@markdown **Mobile**: Tap hamburger (‚ò∞) ‚Üí file browser ‚Üí long press file ‚Üí copy path\n\nvideo_file = \"\" #@param {type:\"string\"}\nvocal_file = \"\" #@param {type:\"string\"}\n\n#@markdown > üí° Leave vocal_file blank if audio is already in the video\n\n#@markdown ---\n#@markdown ## üé® Quality & Processing Options\n\npreset_config = \"Custom\" #@param [\"Custom\", \"High Quality\", \"Fast Processing\", \"Balanced\", \"Ultra High Quality\", \"Mobile Optimized\"]\n\nquality = \"Enhanced\" #@param [\"Fast\", \"Improved\", \"Enhanced\", \"Professional\"]\n#@markdown * **Fast**: Basic Wav2Lip processing\n#@markdown * **Improved**: Wav2Lip + feathered mask  \n#@markdown * **Enhanced**: Wav2Lip + mask + upscaling\n#@markdown * **Professional**: All enhancements + advanced post-processing\n\noutput_height = \"full resolution\" #@param [\"360\", \"480\", \"720\", \"1080\", \"1440\", \"4K\", \"half resolution\", \"full resolution\"] {allow-input: true}\noutput_format = \"mp4\" #@param [\"mp4\", \"avi\", \"mov\", \"mkv\", \"webm\"]\nfps_control = \"auto\" #@param [\"auto\", \"24\", \"25\", \"30\", \"60\"] {allow-input: true}\n\n#@markdown ## üß† AI Model Selection\nwav2lip_version = \"Wav2Lip\" #@param [\"Wav2Lip\", \"Wav2Lip_GAN\"]\nsr_model = \"gfpgan\" #@param [\"gfpgan\", \"realesrgan\", \"codeformer\", \"none\"]\nface_detection_model = \"retinaface\" #@param [\"retinaface\", \"yolov5\", \"mtcnn\", \"blazeface\"]\nmouth_tracking_backend = \"dlib\" #@param [\"dlib\", \"mediapipe\", \"face_alignment\"]\n\n#@markdown ## ‚ö° Performance Options\nuse_previous_tracking_data = True #@param {type:\"boolean\"}\nenable_gpu_acceleration = True #@param {type:\"boolean\"}\nbatch_size = 16 #@param {type:\"slider\", min:1, max:32, step:1}\nnum_workers = 4 #@param {type:\"slider\", min:1, max:8, step:1}\nmemory_efficient_mode = False #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown ## üéØ Advanced Controls\n\n#@markdown ### Face Detection & Tracking\nface_detection_confidence = 0.5 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\nface_margin_top = 0.0 #@param {type:\"slider\", min:-0.5, max:0.5, step:0.05}\nface_margin_bottom = 0.1 #@param {type:\"slider\", min:-0.5, max:0.5, step:0.05}\nface_margin_left = 0.0 #@param {type:\"slider\", min:-0.5, max:0.5, step:0.05}\nface_margin_right = 0.0 #@param {type:\"slider\", min:-0.5, max:0.5, step:0.05}\n\n#@markdown ### Motion & Smoothing\nnosmooth = False #@param {type:\"boolean\"}\nmotion_blur_reduction = True #@param {type:\"boolean\"}\ntemporal_consistency = True #@param {type:\"boolean\"}\nsmoothing_kernel_size = 5 #@param {type:\"slider\", min:3, max:15, step:2}\n\n#@markdown ### Padding (Fine-tune face crop)\nU = 0 #@param {type:\"slider\", min:-100, max:100, step:1}\nD = 10 #@param {type:\"slider\", min:-100, max:100, step:1}\nL = 0 #@param {type:\"slider\", min:-100, max:100, step:1}\nR = 0 #@param {type:\"slider\", min:-100, max:100, step:1}\n\n#@markdown ### Mask & Blending\nmask_mode = \"adaptive\" #@param [\"fixed\", \"adaptive\", \"tracked\", \"ai_segmentation\"]\nmask_size = 1.5 #@param {type:\"slider\", min:0.5, max:5.0, step:0.1}\nmask_feathering = 1.0 #@param {type:\"slider\", min:0.0, max:5.0, step:0.1}\nmask_blur_kernel = 15 #@param {type:\"slider\", min:1, max:50, step:2}\nblend_mode = \"normal\" #@param [\"normal\", \"multiply\", \"overlay\", \"soft_light\", \"linear_burn\"]\nmouth_tracking = False #@param {type:\"boolean\"}\nlip_sync_strength = 1.0 #@param {type:\"slider\", min:0.1, max:2.0, step:0.1}\n\n#@markdown ### Color & Enhancement\ncolor_correction = True #@param {type:\"boolean\"}\nbrightness_adjustment = 0.0 #@param {type:\"slider\", min:-0.3, max:0.3, step:0.05}\ncontrast_adjustment = 1.0 #@param {type:\"slider\", min:0.5, max:2.0, step:0.1}\nsaturation_adjustment = 1.0 #@param {type:\"slider\", min:0.0, max:2.0, step:0.1}\ngamma_correction = 1.0 #@param {type:\"slider\", min:0.5, max:2.0, step:0.1}\n\n#@markdown ### Audio Processing\naudio_enhancement = False #@param {type:\"boolean\"}\nnoise_reduction = False #@param {type:\"boolean\"}\naudio_sync_offset = 0 #@param {type:\"slider\", min:-500, max:500, step:10}\naudio_bitrate = \"192k\" #@param [\"128k\", \"192k\", \"256k\", \"320k\"]\n\n#@markdown ---\n#@markdown ## üîß Processing Options\n\nbatch_process = False #@param {type:\"boolean\"}\nprocess_multiple_faces = False #@param {type:\"boolean\"}\nface_selection_mode = \"largest\" #@param [\"largest\", \"center\", \"manual\", \"all\"]\n\noutput_suffix = \"_Enhanced-Wav2Lip\" #@param {type:\"string\"}\ninclude_settings_in_suffix = False #@param {type:\"boolean\"}\nsave_intermediate_files = False #@param {type:\"boolean\"}\ncreate_comparison_video = False #@param {type:\"boolean\"}\n\n#@markdown ### Preview & Debug Options\npreview_input = True #@param {type:\"boolean\"}\npreview_settings = False #@param {type:\"boolean\"}\nframe_to_preview = 100 #@param {type:\"integer\"}\ndebug_mode = False #@param {type:\"boolean\"}\ndebug_mask = False #@param {type:\"boolean\"}\nsave_debug_frames = False #@param {type:\"boolean\"}\n\n#@markdown ### Output Quality\nvideo_codec = \"libx264\" #@param [\"libx264\", \"libx265\", \"av1\", \"vp9\"]\nvideo_bitrate = \"auto\" #@param [\"auto\", \"1M\", \"2M\", \"5M\", \"10M\", \"20M\"] {allow-input: true}\ncrf_quality = 18 #@param {type:\"slider\", min:0, max:51, step:1}\ntwo_pass_encoding = False #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown ## üöÄ Execute Processing\n#@markdown **Click the play button to start processing!** ‚¨ÖÔ∏è\n\n# Load preset configurations if selected\nif preset_config != \"Custom\":\n    try:\n        import json\n        with open('configs/presets/default_presets.json', 'r') as f:\n            presets = json.load(f)\n        \n        preset_map = {\n            \"High Quality\": \"high_quality\",\n            \"Fast Processing\": \"fast_processing\", \n            \"Balanced\": \"balanced\"\n        }\n        \n        if preset_config in preset_map:\n            preset = presets[preset_map[preset_config]]\n            # Apply preset values\n            for key, value in preset.items():\n                if key in globals():\n                    globals()[key] = value\n            print(f\"‚úÖ Applied {preset_config} preset\")\n    except:\n        print(\"‚ö†Ô∏è Could not load preset, using custom settings\")\n\n# Validation\nif not video_file:\n    sys.exit(\"‚ùå Please specify a video file path!\")\n\n# Enhanced configuration generation\nimport configparser\nimport os\n\nconfig = configparser.ConfigParser()\n\n# Main options\noptions = {\n    'video_file': video_file,\n    'vocal_file': vocal_file,\n    'quality': quality,\n    'output_height': output_height,\n    'output_format': output_format,\n    'fps_control': fps_control,\n    'wav2lip_version': wav2lip_version,\n    'sr_model': sr_model,\n    'face_detection_model': face_detection_model,\n    'mouth_tracking_backend': mouth_tracking_backend,\n    'use_previous_tracking_data': use_previous_tracking_data,\n    'enable_gpu_acceleration': enable_gpu_acceleration,\n    'batch_size': batch_size,\n    'num_workers': num_workers,\n    'memory_efficient_mode': memory_efficient_mode,\n    'nosmooth': nosmooth,\n    'motion_blur_reduction': motion_blur_reduction,\n    'temporal_consistency': temporal_consistency,\n    'smoothing_kernel_size': smoothing_kernel_size\n}\n\n# Advanced face detection\nface_detection = {\n    'confidence_threshold': face_detection_confidence,\n    'margin_top': face_margin_top,\n    'margin_bottom': face_margin_bottom,\n    'margin_left': face_margin_left,\n    'margin_right': face_margin_right\n}\n\n# Padding\npadding = {\n    'U': U, 'D': D, 'L': L, 'R': R\n}\n\n# Enhanced mask options\nmask = {\n    'mode': mask_mode,\n    'size': mask_size,\n    'feathering': mask_feathering,\n    'blur_kernel': mask_blur_kernel,\n    'blend_mode': blend_mode,\n    'mouth_tracking': mouth_tracking,\n    'lip_sync_strength': lip_sync_strength,\n    'debug_mask': debug_mask\n}\n\n# Color enhancement\ncolor = {\n    'correction': color_correction,\n    'brightness': brightness_adjustment,\n    'contrast': contrast_adjustment,\n    'saturation': saturation_adjustment,\n    'gamma': gamma_correction\n}\n\n# Audio options\naudio = {\n    'enhancement': audio_enhancement,\n    'noise_reduction': noise_reduction,\n    'sync_offset': audio_sync_offset,\n    'bitrate': audio_bitrate\n}\n\n# Processing options\nprocessing = {\n    'batch_process': batch_process,\n    'multiple_faces': process_multiple_faces,\n    'face_selection': face_selection_mode,\n    'save_intermediate': save_intermediate_files,\n    'create_comparison': create_comparison_video\n}\n\n# Output options\noutput = {\n    'suffix': output_suffix,\n    'include_settings_in_suffix': include_settings_in_suffix,\n    'codec': video_codec,\n    'bitrate': video_bitrate,\n    'crf_quality': crf_quality,\n    'two_pass': two_pass_encoding\n}\n\n# Debug options\ndebug = {\n    'preview_input': preview_input,\n    'preview_settings': preview_settings,\n    'frame_to_preview': frame_to_preview,\n    'debug_mode': debug_mode,\n    'save_debug_frames': save_debug_frames\n}\n\n# Add sections to config\nconfig['OPTIONS'] = {k: str(v) for k, v in options.items()}\nconfig['FACE_DETECTION'] = {k: str(v) for k, v in face_detection.items()}\nconfig['PADDING'] = {k: str(v) for k, v in padding.items()}\nconfig['MASK'] = {k: str(v) for k, v in mask.items()}\nconfig['COLOR'] = {k: str(v) for k, v in color.items()}\nconfig['AUDIO'] = {k: str(v) for k, v in audio.items()}\nconfig['PROCESSING'] = {k: str(v) for k, v in processing.items()}\nconfig['OUTPUT'] = {k: str(v) for k, v in output.items()}\nconfig['DEBUG'] = {k: str(v) for k, v in debug.items()}\n\n# Save enhanced configuration\nwith open('config.ini', 'w') as f:\n    config.write(f)\n\n# Display processing summary\nprint(\"üé¨ Enhanced Wav2Lip Processing Summary:\")\nprint(f\"üìπ Input Video: {os.path.basename(video_file) if video_file else 'None'}\")\nprint(f\"üéµ Audio: {os.path.basename(vocal_file) if vocal_file else 'From video'}\")\nprint(f\"‚öôÔ∏è Quality: {quality}\")\nprint(f\"üìê Resolution: {output_height}\")\nprint(f\"ü§ñ AI Model: {wav2lip_version} + {sr_model}\")\nprint(f\"üéØ Face Detection: {face_detection_model}\")\nprint(f\"üëÑ Mouth Tracking: {mouth_tracking_backend}\")\nprint(\"=\" * 50)\n\n# Start processing timer\nstart_time = time.time()\nprint(\"üöÄ Starting enhanced processing...\")\n\n# Run the enhanced processing\n!python run.py\n\n# Show results\nfrom easy_functions import show_video\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\n\nif preview_settings:\n    if os.path.isfile(os.path.join('temp','preview.jpg')):\n        print(\"üñºÔ∏è Preview Frame:\")\n        display(Image(os.path.join('temp','preview.jpg')))\nelse:\n    output_path = os.path.join('temp','output.mp4')\n    if os.path.isfile(output_path):\n        print(\"‚úÖ Processing complete!\")\n        \n        # Calculate processing time\n        elapsed_time = time.time() - start_time\n        from easy_functions import format_time\n        print(f\"‚è±Ô∏è Processing time: {format_time(elapsed_time)}\")\n        \n        # Show video preview\n        print(\"üé¨ Loading video preview...\")\n        show_video(output_path)\n        \n        # Display processing stats if available\n        if os.path.exists('temp/processing_stats.json'):\n            import json\n            with open('temp/processing_stats.json', 'r') as f:\n                stats = json.load(f)\n            print(\"\\nüìä Processing Statistics:\")\n            for key, value in stats.items():\n                print(f\"  {key}: {value}\")\n    else:\n        print(\"‚ùå Processing failed. Check the logs above for errors.\")\n\nprint(\"\\nüéâ Enhanced Wav2Lip processing complete!\")",
   "metadata": {
    "id": "akznIwTZK_o8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "outputId": "9dcb5d81-2e07-447f-dcff-b585a6c83f35",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}